{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the figures / plots inside the notebook\n",
    "def show_images(images, titles=None):\n",
    "    # This function is used to show image(s) with titles by sending an array of images\n",
    "    # and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    n_ims = len(images)\n",
    "    if titles is None:\n",
    "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image, title in zip(images, titles):\n",
    "        a = fig.add_subplot(1, n_ims, n)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Data Acquisition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []    # The images of the training dataset\n",
    "y_train = []    # The correct label of each image of the training dataset\n",
    "z_train = []    # The name of each image of the training dataset (for debugging purposes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male data acquisition\n",
    "for file_name in sorted(glob.glob('../Training Dataset/CMP_23/Males/*.jpg')):\n",
    "    img = cv2.imread(file_name)      # cv2.imread reads images in RGB format\n",
    "    x_train.append(img)\n",
    "    y_train.append(1)\n",
    "    z_train.append(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female data acquisition\n",
    "for file_name in sorted(glob.glob('../Training Dataset/CMP_23/Females/*.jpg')):\n",
    "    img = cv2.imread(file_name)      # cv2.imread reads images in RGB format\n",
    "    x_train.append(img)\n",
    "    y_train.append(0)\n",
    "    z_train.append(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "z_train = np.asarray(z_train)\n",
    "print(f\"Size of the training dataset is: {x_train.shape[0]} ({np.sum(y_train)} males, {x_train.shape[0] - np.sum(y_train)} females)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image: np.ndarray, sharpness_factor=10, bordersize=3):\n",
    "    image = Image.fromarray(image)\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    image = enhancer.enhance(sharpness_factor)\n",
    "\n",
    "    (height, width) = (image.height * 2, image.width * 2)\n",
    "    image = image.resize((width, height))\n",
    "\n",
    "    image = np.asarray(image)\n",
    "    image = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        top=bordersize,\n",
    "        bottom=bordersize,\n",
    "        left=bordersize,\n",
    "        right=bordersize,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=[255, 255, 255]\n",
    "    )\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    (_, preprocessed_image) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    return preprocessed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = preprocess_image(x_train[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Feature Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Hinge Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ANGLE_BINS = 40\n",
    "BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "LEG_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_pixels(preprocessed_image: np.ndarray):\n",
    "    contours, _ = cv2.findContours(preprocessed_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "\n",
    "    image2 = preprocessed_image.copy()[:, :, np.newaxis]\n",
    "    image2 = np.concatenate([image2, image2, image2], axis=2)\n",
    "    return contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hinge_features(preprocessed_image: np.ndarray):\n",
    "    contours = get_contour_pixels(preprocessed_image)\n",
    "\n",
    "    hist = np.zeros((N_ANGLE_BINS, N_ANGLE_BINS))\n",
    "\n",
    "    for cnt in contours:\n",
    "        n_pixels = len(cnt)\n",
    "        if n_pixels <= LEG_LENGTH:\n",
    "            continue\n",
    "\n",
    "        points = np.array([point[0] for point in cnt])\n",
    "        (xs, ys) = (points[:, 0], points[:, 1])\n",
    "        point_1s = np.array([cnt[(i + LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "        point_2s = np.array([cnt[(i - LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "        (x1s, y1s) = (point_1s[:, 0], point_1s[:, 1])\n",
    "        (x2s, y2s) = (point_2s[:, 0], point_2s[:, 1])\n",
    "\n",
    "        phi_1s = np.degrees(np.arctan2(y1s - ys, x1s - xs) + np.pi)\n",
    "        phi_2s = np.degrees(np.arctan2(y2s - ys, x2s - xs) + np.pi)\n",
    "\n",
    "        indices = np.where(phi_2s > phi_1s)[0]\n",
    "\n",
    "        for i in indices:\n",
    "            phi1 = int(phi_1s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "            phi2 = int(phi_2s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "            hist[phi1, phi2] += 1\n",
    "\n",
    "    normalized_hist = hist / np.sum(hist)\n",
    "    feature_vector = normalized_hist[np.triu_indices_from(normalized_hist, k=1)]\n",
    "\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge_feature_vector = []\n",
    "for i in range(len(x_train)):\n",
    "    hinge_feature_vector.append(get_hinge_features(x_train[i]))\n",
    "hinge_feature_vector = np.asarray(hinge_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hinge_feature_vector.shape)\n",
    "print(type(hinge_feature_vector[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Model Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47b0946bdb42e5a8db21df9138f17b5cb1a6507cd769a113b48a94aa211b3a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
